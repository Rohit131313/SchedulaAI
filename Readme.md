# ğŸ“… SchedulaAI

SchedulaAI is a conversational AI scheduling assistant that takes natural language input from users, extracts task details (date, time, task), checks Google Calendar for availability, and either books the slot or suggests alternatives. It's built using **LangGraph**, **Google Calendar API**, **FastAPI**, and **Streamlit**.

---

## ğŸ”— Live Demo

ğŸ‘‰ [Visit Streamlit App](https://schedulaai.streamlit.app/)

---

## ğŸ§  How It Works

```

User Input â†’ LangGraph AI Agent â†’
â†’ Extract Time & Task â†’
â†’ Check Google Calendar Availability â†’
â†’ Schedule if free, suggest if busy â†’
â†’ Return final message to frontend

```

---

## ğŸ–¼ï¸ Flow Diagram

![LangGraph Workflow](ai_agent/graph.png)

---

## âš™ï¸ Technologies Used

- `LangGraph` â€” for multi-step agent workflow
- `FastAPI` â€” as backend server
- `Streamlit` â€” frontend interface
- `Google Calendar API` â€” for scheduling
- `LangChain + Gemini API` â€” for task + time extraction
- `dotenv`, `Pydantic` â€” config + validation

---

## ğŸ—‚ï¸ Project Structure

```

â”œâ”€â”€ ai\_agent/
â”‚   â”œâ”€â”€ chains/
â”‚   â”‚   â””â”€â”€ extract\_chain.py         # LLM prompt to extract task/time
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ check\_availability.py    # Checks GCal slot availability
â”‚   â”‚   â”œâ”€â”€ extract\_information.py   # Parses extracted values
â”‚   â”‚   â”œâ”€â”€ settask\_in\_calendar.py   # Books slot in calendar
â”‚   â”œâ”€â”€ state.py                     # Shared LangGraph state
â”‚   â”œâ”€â”€ graph.py                     # Defines LangGraph flow
â”‚   â””â”€â”€ graph.png                    # Visual diagram of agent flow
â”‚   
|
â”œâ”€â”€ agent\_runner.py                  # LangGraph agent runner
â””â”€â”€ credentials.json             # Google OAuth credentials
â”œâ”€â”€ app.py                           # FastAPI backend
â”œâ”€â”€ main.py                          # Streamlit frontend
â”œâ”€â”€ .env                             # Environment vars (API keys etc.)
â”œâ”€â”€ requirements.txt                 # Python dependencies

```

---

## ğŸ“¦ API Endpoint

FastAPI backend (hosted on Render) processes scheduling:

```

POST [https://schedulaai.onrender.com/process/](https://schedulaai.onrender.com/process/)
Body:
{
"input": "Schedule a call with Rohit next Thursday at 4pm"
}

````

---

## ğŸŒ Local vs Remote Backend Setup

By default, the frontend uses the hosted backend (`https://schedulaai.onrender.com`).  
To run locally, modify your `main.py`:

```python
response = requests.post(
    "http://localhost:8000/process/",  # Change this for local testing
    json={"input": user_input}
)
````

---

## ğŸ” .env File (required)

Create a `.env` file at the root level:

```env
GOOGLE_API_KEY=your-gemini-api-key
```


### ğŸ” Google Calendar Setup (credentials.json)

To enable Google Calendar access, you must place your **Google OAuth credentials** file in project folder

#### ğŸ“ Required File

```
credentials.json
```

#### ğŸªª How to Generate Your Own `credentials.json`

1. Go to the [Google Cloud Console](https://console.cloud.google.com/).
2. Create a new project (or select an existing one).
3. Navigate to **"APIs & Services" > "Credentials"**.
4. Click **"Create Credentials"** > **"OAuth client ID"**.
5. Choose **"Desktop App"** as the application type.
6. Download the generated `credentials.json`.

#### ğŸ“Œ Donâ€™t Forget
âœ… Enable Google Calendar API
Go to the Google API Library and enable the Google Calendar API for your project.

ğŸ‘¤ Add Test User Email
If you're using OAuth client credentials, make sure to add your Google account as a test user in the OAuth consent screen.

ğŸ” Authorize on First Run
The first time you run the project locally, a browser window will prompt you to log in with your Google account and authorize calendar access.



---

## ğŸ› ï¸ Setup Instructions (Local)

```bash
# Clone the repo
git clone https://github.com/Rohit131313/SchedulaAI.git
cd SchedulaAI

# Create virtual environment
conda create -n schedulaai python=3.10
conda activate schedulaai

# Install required packages
pip install -r requirements.txt

# Run backend
uvicorn app:app --reload

# Run frontend
streamlit run main.py
```

---

## ğŸ§  LangGraph Flow Summary

LangGraph handles a 3-step AI agent workflow:

1. **extract\_information.py**
   â¤ Uses Gemini to extract structured datetime and task info.

2. **check\_availability.py**
   â¤ Queries Google Calendar for conflicting events.

3. **settask\_in\_calendar.py**
   â¤ Schedules the task if free; suggests otherwise.

All connected via `graph.py` using `LangGraph`.

---

## âœ¨ Sample Interaction

```
User: "Book a call with Rohit next Thursday at 3 PM"
â†’ Gemini extracts: start_time, end_time, task
â†’ Checks Google Calendar
â†’ If free: schedules task + returns link
â†’ If busy: returns free time suggestions
```

---

## ğŸ“¸ Screenshot Output (Example UI)

![Streamlit UI](photos/streamlit_screenshot.png)
![Calendar Event](photos/Calender.png)
![Logs](photos/Logs.png)

---

## âœ… Deployment Support

* Hosted Backend: Render
* Hosted Frontend: Streamlit Cloud
* Includes `.env` and credential setup

